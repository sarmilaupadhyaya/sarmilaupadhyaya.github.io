<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>python on ü§ì Sharmila Upadhyaya ü§ì</title>
    <link>https://sarmilaupadhyaya.github.io/tags/python/</link>
    <description>Recent content in python on ü§ì Sharmila Upadhyaya ü§ì</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Wed, 06 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://sarmilaupadhyaya.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Loading Dataset into Google Collaboration using different way</title>
      <link>https://sarmilaupadhyaya.github.io/posts/2019/11/loading-dataset-into-google-collaboration-using-different-way/</link>
      <pubDate>Wed, 06 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sarmilaupadhyaya.github.io/posts/2019/11/loading-dataset-into-google-collaboration-using-different-way/</guid>
      <description>Google collab provides an ubiquitous platform for all of us, with different hardware selection (CPU, GPU and TPU) band 12 GB of RAM (25 GB if your session crashes. I sometimes willingly crash the collab with some sample of code so that I will get 25 GB of ram for that particular session). At least in the case of training any model, I, personally prefer google collab to build and train my model.</description>
    </item>
    
    <item>
      <title>Building Chatbot using RASA NLU. Part I</title>
      <link>https://sarmilaupadhyaya.github.io/posts/2019/10/building-chatbot-using-rasa-nlu.-part-i/</link>
      <pubDate>Thu, 31 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sarmilaupadhyaya.github.io/posts/2019/10/building-chatbot-using-rasa-nlu.-part-i/</guid>
      <description>In this tutorial, we will be setting up RASA and making a simple chatbot with it. This chatbot will answer the questions about snacks and acknowledge the user&amp;rsquo;s response. It will be the simplest chatbot ever. This is part one of the rasa series. We will be covering the installation and simple usage of RASA only.
What is RASA?
It is an open-source machine learning framework to create virtual assistants/chatbots. It uses NLP pipelines and architecture for a chatbot and provides excellent flow.</description>
    </item>
    
    <item>
      <title>Loading Glove Pre-trained Word Embedding Model from Text File [Faster]</title>
      <link>https://sarmilaupadhyaya.github.io/posts/2019/09/loading-glove-pre-trained-word-embedding-model-from-text-file-faster/</link>
      <pubDate>Wed, 11 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://sarmilaupadhyaya.github.io/posts/2019/09/loading-glove-pre-trained-word-embedding-model-from-text-file-faster/</guid>
      <description>With the evolution of transfer learning approaches in image processing, the field of Natural Language Processing has also a ubiquitous pre-trained model which is used for multiple states of the art transfer learning solutions for Text classification, Named Entity Recognition.
And this pre-trained model is Word Embeddings. Word embedding is a vector representation of vocabulary which is trained following the concept ‚Äúmeaning of the word is carried by its correspondence‚Äù Excuse me if I have misphrased Ahem!</description>
    </item>
    
  </channel>
</rss>